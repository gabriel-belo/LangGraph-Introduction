{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774aa386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "messages = [AIMessage(content=f\"So you said you were researching ocean mammals?\", name=\"Model\")]\n",
    "messages.append(HumanMessage(content=f\"Yes, that's right.\",name=\"Lance\"))\n",
    "messages.append(AIMessage(content=f\"Great, what would you like to learn about.\", name=\"Model\"))\n",
    "messages.append(HumanMessage(content=f\"I want to learn about the best place to see Orcas in the US.\", name=\"Lance\"))\n",
    "\n",
    "for m in messages:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec938f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c9d5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm= ChatOpenAI(model=\"gpt-4o\")\n",
    "result= llm.invoke(messages)\n",
    "type(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0f5ca7",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199b14b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int)->int:\n",
    "    \"\"\"Multiply a and b\n",
    "    \n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "\n",
    "    return a * b\n",
    "\n",
    "llm_with_tools= llm.bind_tools([multiply])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8256482a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call= llm_with_tools.invoke([HumanMessage(content=f\"What is 2 multiplied by 3\", name= \"Lance\")])\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852048aa",
   "metadata": {},
   "source": [
    "## Usando mensagens como estado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e90ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: list[AnyMessage]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1d2ef1",
   "metadata": {},
   "source": [
    "## Reducers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afabf984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3255273",
   "metadata": {},
   "source": [
    "Como ter uma lista de mensagens no estado do grafo √© muito comum, o LangGraph j√° vem com um MessagesState pr√©-constru√≠do!\n",
    "\n",
    "O MessagesState √© definido:\n",
    "\n",
    "Com uma chave √∫nica de mensagens pr√©-constru√≠da\n",
    "\n",
    "Esta √© uma lista de objetos AnyMessage\n",
    "\n",
    "Ele usa o reducer add_messages\n",
    "\n",
    "Normalmente usamos o MessagesState porque ele √© menos verboso do que definir um TypedDict personalizado, como mostrado acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e366f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class MessagesState(MessagesState):\n",
    "    # Add any keys needed beyond messages, which is pre-built \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97d8e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial state\n",
    "initial_messages = [AIMessage(content=\"Hello! How can I assist you?\", name=\"Model\"),\n",
    "                    HumanMessage(content=\"I'm looking for information on marine biology.\", name=\"Lance\")\n",
    "                   ]\n",
    "\n",
    "# New message to add\n",
    "new_message = AIMessage(content=\"Sure, I can help with that. What specifically are you interested in?\", name=\"Model\")\n",
    "\n",
    "# Test\n",
    "add_messages(initial_messages , new_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65351a93",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecee82c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "    \n",
    "# Node\n",
    "def tool_calling_llm(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_edge(\"tool_calling_llm\", END)\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b31c51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Hello!\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060392d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Multiply 2 and 3\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ece2f8c",
   "metadata": {},
   "source": [
    "## Resumo da Diferen√ßa (Entrada/Cria√ß√£o)\n",
    "\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>M√©todo de Defini√ß√£o</th>\n",
    "            <th>O que voc√™ cria para o invoke()</th>\n",
    "            <th>Formato da Entrada para graph.invoke()</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>@dataclass</td>\n",
    "            <td>Uma inst√¢ncia da classe</td>\n",
    "            <td>Objeto de classe: <code>graph.invoke(DataclassState(...))</code></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Pydantic (BaseModel)</td>\n",
    "            <td>Uma inst√¢ncia da classe</td>\n",
    "            <td>Objeto de classe: <code>graph.invoke(PydanticState(...))</code></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>TypedDict</td>\n",
    "            <td>Um dicion√°rio</td>\n",
    "            <td>Dicion√°rio: <code>graph.invoke({\"key\": value, ...})</code></td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\n",
    "Tanto dataclass quanto Pydantic incentivam o paradigma da Programa√ß√£o Orientada a Objetos (cria√ß√£o de inst√¢ncias).\n",
    "\n",
    "## üîÑ Similaridade (Sa√≠da/Atualiza√ß√£o)\n",
    "\n",
    "Apesar da diferen√ßa na forma como o estado √© criado inicialmente, na sa√≠da de um n√≥ (o que voc√™ return da fun√ß√£o do n√≥), voc√™ sempre retorna um dicion√°rio que representa as mudan√ßas incrementais de estado.\n",
    "\n",
    "Isso acontece porque o LangGraph usa o operador de uni√£o para mesclar o estado retornado com o estado anterior:\n",
    "\n",
    "* Estado Anterior: LangGraph mant√©m o estado completo (seja ele internamente um objeto ou um dicion√°rio).\n",
    "\n",
    "* Retorno do N√≥: Seu n√≥ retorna um dicion√°rio (ex: {\"mood\": \"happy\"}).\n",
    "\n",
    "* Fus√£o: O LangGraph funde (merge) esse dicion√°rio com o estado anterior. Se voc√™ usou uma classe (Pydantic/Dataclass), o LangGraph garante que a fus√£o respeite o esquema da classe.\n",
    "\n",
    "Isso significa que, independentemente do tipo de estado que voc√™ escolher:\n",
    "\n",
    "* Para Ler: Voc√™ usa o formato de acesso do tipo (state.key ou state[\"key\"]).\n",
    "\n",
    "* Para Atualizar: Voc√™ sempre retorna um dicion√°rio contendo apenas as chaves que deseja alterar."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
