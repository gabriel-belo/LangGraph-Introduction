{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48f075ff",
   "metadata": {},
   "source": [
    "## Parallel  node execution (Execução paralela de nós)\n",
    "#### Revisão\n",
    "\n",
    "No módulo 3, aprofundamos o conceito de interação humana, mostrando 3 casos de uso comuns:\n",
    "\n",
    "(1) Aprovação - Podemos interromper nosso agente, expor o estado a um usuário e permitir que ele aceite uma ação.\n",
    "\n",
    "(2) Depuração - Podemos retroceder o grafo para reproduzir ou evitar problemas.\n",
    "\n",
    "(3) Edição - Você pode modificar o estado.\n",
    "\n",
    "#### Objetivos\n",
    "Este módulo aprofundará o conceito de interação humana, bem como os conceitos de memória discutidos no módulo 2.\n",
    "\n",
    "Vamos explorar fluxos de trabalho multiagentes e construir um assistente de pesquisa multiagente que integre todos os módulos deste curso.\n",
    "\n",
    "Para construir este assistente de pesquisa multiagente, primeiro discutiremos alguns tópicos de controlabilidade do LangGraph.\n",
    "\n",
    "Começaremos com a paralelização.\n",
    "\n",
    "Expansão e refinamento\n",
    "Vamos construir um grafo linear simples que sobrescreve o estado a cada passo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2382e1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7badbf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from typing import Any, List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Note, no reducer function. \n",
    "    state: List[str]\n",
    "\n",
    "class ReturnNodeValue:\n",
    "    def __init__(self, node_secret: str):\n",
    "        self._value = node_secret\n",
    "\n",
    "    def __call__(self, state: State) -> Any:\n",
    "        print(f\"Adding {self._value} to {state['state']}\")\n",
    "        return {\"state\": [self._value]}\n",
    "\n",
    "# Add nodes\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# Initialize each node with node_secret \n",
    "builder.add_node(\"a\", ReturnNodeValue(\"I'm A\"))\n",
    "builder.add_node(\"b\", ReturnNodeValue(\"I'm B\"))\n",
    "builder.add_node(\"c\", ReturnNodeValue(\"I'm C\"))\n",
    "builder.add_node(\"d\", ReturnNodeValue(\"I'm D\"))\n",
    "\n",
    "# Flow\n",
    "builder.add_edge(START, \"a\")\n",
    "builder.add_edge(\"a\", \"b\")\n",
    "builder.add_edge(\"b\", \"c\")\n",
    "builder.add_edge(\"c\", \"d\")\n",
    "builder.add_edge(\"d\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e394ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke({\"state\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301096f3",
   "metadata": {},
   "source": [
    "Agora, vamos executar b e c em paralelo.\n",
    "\n",
    "E depois executar d.\n",
    "\n",
    "Podemos fazer isso facilmente com fan-out de a para b e c, e depois fan-in para d.\n",
    "\n",
    "As atualizações de estado são aplicadas ao final de cada etapa.\n",
    "\n",
    "Vamos executar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7878cda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(State)\n",
    "\n",
    "# Initialize each node with node_secret \n",
    "builder.add_node(\"a\", ReturnNodeValue(\"I'm A\"))\n",
    "builder.add_node(\"b\", ReturnNodeValue(\"I'm B\"))\n",
    "builder.add_node(\"c\", ReturnNodeValue(\"I'm C\"))\n",
    "builder.add_node(\"d\", ReturnNodeValue(\"I'm D\"))\n",
    "\n",
    "# Flow\n",
    "builder.add_edge(START, \"a\")\n",
    "builder.add_edge(\"a\", \"b\")\n",
    "builder.add_edge(\"a\", \"c\")\n",
    "builder.add_edge(\"b\", \"d\")\n",
    "builder.add_edge(\"c\", \"d\")\n",
    "builder.add_edge(\"d\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa49b32e",
   "metadata": {},
   "source": [
    "Isso ocorre porque tanto b quanto c estão escrevendo na mesma chave de estado/canal na mesma etapa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c311cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.errors import InvalidUpdateError\n",
    "try:\n",
    "    graph.invoke({\"state\": []})\n",
    "except InvalidUpdateError as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2ada29",
   "metadata": {},
   "source": [
    "Ao usar o recurso de \"fan out\", precisamos garantir que estamos usando um reducer se as etapas estiverem escrevendo no mesmo canal/chave.\n",
    "\n",
    "Como mencionado no Módulo 2, `operator.add` é uma função do módulo `operator` do Python.\n",
    "\n",
    "Quando `operator.add` é aplicado a listas, ele realiza a concatenação das listas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ea953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated\n",
    "\n",
    "class State(TypedDict):\n",
    "    # The operator.add reducer fn makes this append-only\n",
    "    state: Annotated[list, operator.add]\n",
    "\n",
    "# Add nodes\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# Initialize each node with node_secret \n",
    "builder.add_node(\"a\", ReturnNodeValue(\"I'm A\"))\n",
    "builder.add_node(\"b\", ReturnNodeValue(\"I'm B\"))\n",
    "builder.add_node(\"c\", ReturnNodeValue(\"I'm C\"))\n",
    "builder.add_node(\"d\", ReturnNodeValue(\"I'm D\"))\n",
    "\n",
    "# Flow\n",
    "builder.add_edge(START, \"a\")\n",
    "builder.add_edge(\"a\", \"b\")\n",
    "builder.add_edge(\"a\", \"c\")\n",
    "builder.add_edge(\"b\", \"d\")\n",
    "builder.add_edge(\"c\", \"d\")\n",
    "builder.add_edge(\"d\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84149aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke({\"state\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1c4073",
   "metadata": {},
   "source": [
    "Agora vemos que adicionamos ao estado as atualizações feitas em paralelo por b e c."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f3fe6f",
   "metadata": {},
   "source": [
    "Aguardando a conclusão dos nós\n",
    "Agora, vamos considerar um caso em que um caminho paralelo tenha mais etapas do que o outro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6a2ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(State)\n",
    "\n",
    "# Initialize each node with node_secret \n",
    "builder.add_node(\"a\", ReturnNodeValue(\"I'm A\"))\n",
    "builder.add_node(\"b\", ReturnNodeValue(\"I'm B\"))\n",
    "builder.add_node(\"b2\", ReturnNodeValue(\"I'm B2\"))\n",
    "builder.add_node(\"c\", ReturnNodeValue(\"I'm C\"))\n",
    "builder.add_node(\"d\", ReturnNodeValue(\"I'm D\"))\n",
    "\n",
    "# Flow\n",
    "builder.add_edge(START, \"a\")\n",
    "builder.add_edge(\"a\", \"b\")\n",
    "builder.add_edge(\"a\", \"c\")\n",
    "builder.add_edge(\"b\", \"b2\")\n",
    "builder.add_edge([\"b2\", \"c\"], \"d\")\n",
    "builder.add_edge(\"d\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380f5ecf",
   "metadata": {},
   "source": [
    "Neste caso, b, b2 e c fazem parte da mesma etapa.\n",
    "\n",
    "O gráfico aguardará a conclusão de todas essas etapas antes de prosseguir para a etapa d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0bce5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke({\"state\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587c4e62",
   "metadata": {},
   "source": [
    "### Definindo a ordem das atualizações de estado\n",
    "\n",
    "No entanto, em cada etapa, não temos controle específico sobre a ordem das atualizações de estado!\n",
    "\n",
    "Em termos simples, trata-se de uma ordem determinística definida pelo LangGraph com base na topologia do grafo, que não controlamos.\n",
    "\n",
    "Acima, vemos que c é adicionado antes de b2.\n",
    "\n",
    "Contudo, podemos usar um reducer personalizado para personalizar isso, por exemplo, ordenando as atualizações de estado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e376b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorting_reducer(left, right):\n",
    "    \"\"\" Combines and sorts the values in a list\"\"\"\n",
    "    if not isinstance(left, list):\n",
    "        left = [left]\n",
    "\n",
    "    if not isinstance(right, list):\n",
    "        right = [right]\n",
    "    \n",
    "    return sorted(left + right, reverse=False)\n",
    "\n",
    "class State(TypedDict):\n",
    "    # sorting_reducer will sort the values in state\n",
    "    state: Annotated[list, sorting_reducer]\n",
    "\n",
    "# Add nodes\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# Initialize each node with node_secret \n",
    "builder.add_node(\"a\", ReturnNodeValue(\"I'm A\"))\n",
    "builder.add_node(\"b\", ReturnNodeValue(\"I'm B\"))\n",
    "builder.add_node(\"b2\", ReturnNodeValue(\"I'm B2\"))\n",
    "builder.add_node(\"c\", ReturnNodeValue(\"I'm C\"))\n",
    "builder.add_node(\"d\", ReturnNodeValue(\"I'm D\"))\n",
    "\n",
    "# Flow\n",
    "builder.add_edge(START, \"a\")\n",
    "builder.add_edge(\"a\", \"b\")\n",
    "builder.add_edge(\"a\", \"c\")\n",
    "builder.add_edge(\"b\", \"b2\")\n",
    "builder.add_edge([\"b2\", \"c\"], \"d\")\n",
    "builder.add_edge(\"d\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1984006c",
   "metadata": {},
   "source": [
    "Agora, o reducer ordena os valores de estado atualizados!\n",
    "\n",
    "O exemplo sorting_reducer ordena todos os valores globalmente. Também podemos:\n",
    "\n",
    "1. Escrever as saídas em um campo separado no estado durante a etapa paralela.\n",
    "2. Usar um nó \"sink\" após a etapa paralela para combinar e ordenar essas saídas.\n",
    "3. Limpar o campo temporário após a combinação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0e0a44",
   "metadata": {},
   "source": [
    "### Trabalhando com LLMs\n",
    "\n",
    "Agora, vamos adicionar um exemplo realista!\n",
    "\n",
    "Queremos coletar contexto de duas fontes externas (Wikipedia e Busca na Web) e pedir a um LLM que responda a uma pergunta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c664e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm= ChatOpenAI(model=\"gpt-4o\", temperature= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72a224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    answer: str\n",
    "    context: Annotated[list, operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294746d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "_set_env(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b727612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain_tavily import TavilySearch  # updated since filming\n",
    "\n",
    "def search_web(state):\n",
    "    \n",
    "    \"\"\" Retrieve docs from web search \"\"\"\n",
    "\n",
    "    # Search\n",
    "    tavily_search = TavilySearch(max_results=3)\n",
    "    data = tavily_search.invoke({\"query\": state['question']})\n",
    "    search_docs = data.get(\"results\", data)\n",
    "\n",
    "     # Format\n",
    "    formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
    "        [\n",
    "            f'<Document href=\"{doc[\"url\"]}\">\\n{doc[\"content\"]}\\n</Document>'\n",
    "            for doc in search_docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return {\"context\": [formatted_search_docs]} \n",
    "\n",
    "def search_wikipedia(state):\n",
    "    \n",
    "    \"\"\" Retrieve docs from wikipedia \"\"\"\n",
    "\n",
    "    # Search\n",
    "    search_docs = WikipediaLoader(query=state['question'], \n",
    "                                  load_max_docs=2).load()\n",
    "\n",
    "     # Format\n",
    "    formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
    "        [\n",
    "            f'<Document source=\"{doc.metadata[\"source\"]}\" page=\"{doc.metadata.get(\"page\", \"\")}\">\\n{doc.page_content}\\n</Document>'\n",
    "            for doc in search_docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return {\"context\": [formatted_search_docs]} \n",
    "\n",
    "def generate_answer(state):\n",
    "    \n",
    "    \"\"\" Node to answer a question \"\"\"\n",
    "\n",
    "    # Get state\n",
    "    context = state[\"context\"]\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Template\n",
    "    answer_template = \"\"\"Answer the question {question} using this context: {context}\"\"\"\n",
    "    answer_instructions = answer_template.format(question=question, \n",
    "                                                       context=context)    \n",
    "    \n",
    "    # Answer\n",
    "    answer = llm.invoke([SystemMessage(content=answer_instructions)]+[HumanMessage(content=f\"Answer the question.\")])\n",
    "      \n",
    "    # Append it to state\n",
    "    return {\"answer\": answer}\n",
    "\n",
    "# Add nodes\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# Initialize each node with node_secret \n",
    "builder.add_node(\"search_web\",search_web)\n",
    "builder.add_node(\"search_wikipedia\", search_wikipedia)\n",
    "builder.add_node(\"generate_answer\", generate_answer)\n",
    "\n",
    "# Flow\n",
    "builder.add_edge(START, \"search_wikipedia\")\n",
    "builder.add_edge(START, \"search_web\")\n",
    "builder.add_edge(\"search_wikipedia\", \"generate_answer\")\n",
    "builder.add_edge(\"search_web\", \"generate_answer\")\n",
    "builder.add_edge(\"generate_answer\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb05586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke({\"question\": \"How were Nvidia's Q2 2025 earnings\"})\n",
    "result['answer'].content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc-academy-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
