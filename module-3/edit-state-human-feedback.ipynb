{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6452a381",
   "metadata": {},
   "source": [
    "### Editando state\n",
    "\n",
    "Breakpoints servem para parar a execução, mas também são uma oportunidade para modificar o state do grapho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68ab7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "# This will be a tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide a by b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "tools = [add, multiply, divide]\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19150fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# System message\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")\n",
    "\n",
    "# Node\n",
    "def assistant(state: MessagesState):\n",
    "   return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Define edges: these determine the control flow\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(interrupt_before=[\"assistant\"], checkpointer=memory)\n",
    "\n",
    "# Show\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87135cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "initial_input = {\"messages\": \"Multiply 2 and 3\"}\n",
    "\n",
    "# Thread\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fe0af0",
   "metadata": {},
   "source": [
    "Aplicar um update do state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38678eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.update_state(\n",
    "    thread,\n",
    "    {\"messages\": [HumanMessage(content=\"No, actually multiply 3 and 3 !\")]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441df035",
   "metadata": {},
   "source": [
    "Verificando cada mensagem no state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acccd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_state= graph.get_state(thread).values\n",
    "for m in new_state[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc448cd4",
   "metadata": {},
   "source": [
    "Prosseguindo com o agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589736c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event[\"messages\"].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacb6a66",
   "metadata": {},
   "source": [
    "Repetindo para finalizar, já que ele para sempre ue chega no assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d248abb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event[\"messages\"].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f182b07",
   "metadata": {},
   "source": [
    "### Aguardando entrada do usuário\n",
    "Portanto, fica claro que podemos editar o estado do nosso agente após um ponto de interrupção.\n",
    "\n",
    "Agora, e se quisermos permitir que o feedback humano realize essa atualização de estado?\n",
    "\n",
    "Adicionaremos um nó que servirá como um marcador para o feedback humano dentro do nosso agente.\n",
    "\n",
    "Este nó `human_feedback` permite que o usuário adicione feedback diretamente ao estado.\n",
    "\n",
    "Especificamos o ponto de interrupção usando `interrupt_before` em nosso nó `human_feedback`.\n",
    "\n",
    "Configuramos um ponto de verificação para salvar o estado do grafo até este nó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead6b6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System message\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")\n",
    "\n",
    "# no-op node that should be interrupted on\n",
    "def human_feedback(state: MessagesState):\n",
    "    pass\n",
    "\n",
    "# Assistant node\n",
    "def assistant(state: MessagesState):\n",
    "   return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "builder.add_node(\"human_feedback\", human_feedback)\n",
    "\n",
    "# Define edges: these determine the control flow\n",
    "builder.add_edge(START, \"human_feedback\")\n",
    "builder.add_edge(\"human_feedback\", \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"human_feedback\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(interrupt_before=[\"human_feedback\"], checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabb9865",
   "metadata": {},
   "source": [
    "Iremos receber feedback do usuário.\n",
    "\n",
    "Usamos `.update_state` para atualizar o estado do grafo com a resposta humana recebida, como antes.\n",
    "\n",
    "Usamos o parâmetro `as_node=\"human_feedback\"` para aplicar essa atualização de estado ao nó especificado, `human_feedback`.\n",
    "\n",
    "O parâmetro as_node é uma funcionalidade avançada do LangGraph que permite que você simule a saída de um nó específico ao atualizar o estado de uma thread manualmente (usando graph.update_state).\n",
    "\n",
    "Em essência, ele diz ao LangGraph: \"Ignore a execução do nó, mas trate esta atualização de estado como se tivesse vindo deste nó.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56969dc6",
   "metadata": {},
   "source": [
    "### Funcionamento do as_node\n",
    "No seu código, a linha crucial é:\n",
    "\n",
    "~~~Python\n",
    "\n",
    "graph.update_state(thread, {\"messages\": user_input}, as_node=\"human_feedback\")\n",
    "~~~\n",
    "\n",
    "1. O Propósito da Interrupção\n",
    "O seu grafo é configurado para interromper a execução antes de entrar no nó \"human_feedback\":\n",
    "\n",
    "~~~Python\n",
    "\n",
    "graph = builder.compile(interrupt_before=[\"human_feedback\"], ...)\n",
    "~~~\n",
    "\n",
    "Quando o grafo é executado pela primeira vez, ele para no ponto onde o nó \"human_feedback\" seria chamado. O LangGraph está esperando a entrada externa (o feedback humano) para continuar o fluxo.\n",
    "\n",
    "2. A Simulação com update_state\n",
    "Em vez de deixar o nó \"human_feedback\" executar sua função (que é uma função no-op, ou seja, não faz nada definido como: def human_feedback(state: MessagesState): pass), você usa graph.update_state para injetar dados e simular a conclusão do nó.\n",
    "\n",
    "{\"messages\": user_input}: Este é o dicionário de atualização de estado que você deseja aplicar. Ele adiciona o input do usuário ao histórico de mensagens.\n",
    "\n",
    "as_node=\"human_feedback\": Este parâmetro tem dois efeitos principais:\n",
    "\n",
    "Define o Ponto de Partida: Diz ao LangGraph que o estado atual deve ser atualizado e que a execução deve ser retomada a partir do ponto que se segue ao nó \"human_feedback\" (que, neste caso, é o nó \"assistant\").\n",
    "\n",
    "Define a Fonte da Mudança: O LangGraph registra que a mudança no estado ({\"messages\": user_input}) foi causada pelo nó \"human_feedback\", mesmo que a função real human_feedback não tenha sido executada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bd3690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "initial_input = {\"messages\": \"Multiply 2 and 3\"}\n",
    "\n",
    "# Thread\n",
    "thread = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "    \n",
    "# Get user input\n",
    "user_input = input(\"Tell me how you want to update the state: \")\n",
    "\n",
    "# We now update the state as if we are the human_feedback node\n",
    "graph.update_state(thread, {\"messages\": user_input}, as_node=\"human_feedback\")\n",
    "\n",
    "# Continue the graph execution\n",
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2ac0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue the graph execution\n",
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc-academy-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
